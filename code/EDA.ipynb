{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# 설치된 폰트를 Matplotlib에 적용\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "\n",
    "# 폰트 경로 설정\n",
    "font_dir = \"/usr/share/fonts/truetype/noto\"\n",
    "font_files = fm.findSystemFonts(fontpaths=font_dir)\n",
    "for font_file in font_files:\n",
    "    fm.fontManager.addfont(font_file)\n",
    "\n",
    "# 폰트 설정\n",
    "plt.rcParams['font.family'] = 'Noto Sans CJK JP'\n",
    "\n",
    "\n",
    "# 데이터 불러오기\n",
    "file_path = 'data/train.csv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path, encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    data = pd.read_csv(file_path, encoding='euc-kr')\n",
    "\n",
    "# 대화와 요약의 길이 계산\n",
    "data['dialogue_length'] = data['dialogue'].apply(len)\n",
    "data['summary_length'] = data['summary'].apply(len)\n",
    "\n",
    "# 길이 분포 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data['dialogue_length'], bins=50, color='blue', label='Dialogue Length')\n",
    "sns.histplot(data['summary_length'], bins=50, color='red', label='Summary Length')\n",
    "plt.legend()\n",
    "plt.title('Dialogue and Summary Length Distribution')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 주제별 대화 수 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y='topic', data=data, order=data['topic'].value_counts().index)\n",
    "plt.title('Number of Dialogues per Topic')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Topic')\n",
    "plt.show()\n",
    "\n",
    "# WordCloud 생성 시 폰트 경로 지정\n",
    "font_path = \"/usr/share/fonts/truetype/noto/NotoSansCJKjp-Regular.otf\"\n",
    "\n",
    "# 워드 클라우드 생성\n",
    "dialogue_text = \" \".join(data['dialogue'].values)\n",
    "summary_text = \" \".join(data['summary'].values)\n",
    "\n",
    "dialogue_wordcloud = WordCloud(font_path=font_path, width=800, height=400, background_color='white').generate(dialogue_text)\n",
    "summary_wordcloud = WordCloud(font_path=font_path, width=800, height=400, background_color='white').generate(summary_text)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(dialogue_wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for Dialogues')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(summary_wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for Summaries')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 워드 클라우드 생성\n",
    "topic_text = \" \".join(data['topic'].values)\n",
    "\n",
    "topic_wordcloud = WordCloud(font_path=font_path, width=800, height=400, background_color='white').generate(topic_text)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.imshow(topic_wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for Dialogues')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 주제별 대화 수 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y='topic', data=data, order=data['topic'].value_counts().index)\n",
    "plt.title('Number of Dialogues per Topic')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Topic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "value_counts = data['topic'].value_counts()\n",
    "print(value_counts)\n",
    "print(type(value_counts))\n",
    "\n",
    "# 막대 그래프 생성\n",
    "value_counts[:40].plot(kind='bar')\n",
    "\n",
    "# 그래프에 제목과 레이블 추가\n",
    "plt.title('Value Counts of Topic')\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "# 그래프 보여주기\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # 모델의 성능을 평가하기 위한 라이브러리입니다.\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import wandb # 모델 학습 과정을 손쉽게 Tracking하고, 시각화할 수 있는 라이브러리입니다.\n",
    "\n",
    "# config 설정에 tokenizer 모듈이 사용되므로 미리 tokenizer를 정의해줍니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"../data/\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        \"model_name\": \"digit82/kobart-summarization\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": \"./\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 100,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#']\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 50,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        \"report_to\": \"wandb\" # (선택) wandb를 사용할 때 설정합니다.\n",
    "    },\n",
    "    # (선택) wandb 홈페이지에 가입하여 얻은 정보를 기반으로 작성합니다.\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"wandb_repo\",\n",
    "        \"project\": \"project_name\",\n",
    "        \"name\": \"run_name\"\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"model ckt path\", # 사전 학습이 진행된 모델의 checkpoint를 저장할 경로를 설정합니다.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 100,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 32,\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 모델의 구성 정보를 YAML 파일로 저장합니다.\n",
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 저장된 config 파일을 불러옵니다.\n",
    "config_path = \"./config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "# 불러온 config 파일의 전체 내용을 확인합니다.\n",
    "pprint(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 실험에 쓰일 데이터의 경로, 사용될 모델, 모델의 최종 출력 결과를 저장할 경로에 대해 확인합니다.\n",
    "loaded_config['general']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 이곳에 사용자가 저장한 데이터 dir 설정하기\n",
    "loaded_config['general']['data_path'] = \"/data/ephemeral/home/자연어처리대회/data_original/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리를 하기 위해 tokenization 과정에서 필요한 정보들을 확인합니다.\n",
    "loaded_config['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 모델이 훈련 시 적용될 매개변수를 확인합니다.\n",
    "loaded_config['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 모델 학습 과정에 대한 정보를 제공해주는 wandb 설정 내용을 확인합니다.\n",
    "loaded_config['wandb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# (선택) 이곳에 사용자가 사용할 wandb config 설정\n",
    "loaded_config['wandb']['entity'] = \"ssuksa\"\n",
    "loaded_config['wandb']['name'] = \"NL_test\"\n",
    "loaded_config['wandb']['project'] = \"NL_proj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 모델이 최종 결과를 출력하기 위한 매개변수 정보를 확인합니다.\n",
    "loaded_config['inference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# config에 저장된 데이터 경로를 통해 train과 validation data를 불러옵니다.\n",
    "data_path = loaded_config['general']['data_path']\n",
    "\n",
    "# train data의 구조와 내용을 확인합니다.\n",
    "train_df = pd.read_csv(os.path.join(data_path,'train.csv'))\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "data.loc[599]['dialogue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# validation data의 구조와 내용을 확인합니다.\n",
    "val_df = pd.read_csv(os.path.join(data_path,'dev.csv'))\n",
    "val_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Coding/AILAB_NLP/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Noto Sans CJK 폰트 다운로드\n",
    "url = \"https://noto-website-2.storage.googleapis.com/pkgs/NotoSansCJKjp-hinted.zip\"\n",
    "zip_path = \"/tmp/NotoSansCJK.zip\"\n",
    "font_dir = \"/usr/share/fonts/truetype/noto\"\n",
    "\n",
    "# 폰트 다운로드\n",
    "urllib.request.urlretrieve(url, zip_path)\n",
    "\n",
    "# 폰트 디렉토리 생성\n",
    "os.makedirs(font_dir, exist_ok=True)\n",
    "\n",
    "# 다운로드한 ZIP 파일을 추출\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(font_dir)\n",
    "\n",
    "# 설치된 폰트를 Matplotlib에 적용\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 폰트 경로 설정\n",
    "font_files = fm.findSystemFonts(fontpaths=font_dir)\n",
    "for font_file in font_files:\n",
    "    fm.fontManager.addfont(font_file)\n",
    "\n",
    "# 폰트 설정\n",
    "plt.rcParams['font.family'] = 'Noto Sans CJK JP'\n",
    "\n",
    "# 테스트 그래프 그리기\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.text(0.5, 0.5, '한글 폰트 테스트', fontsize=20, ha='center')\n",
    "plt.title('Noto Sans CJK JP 사용')\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
